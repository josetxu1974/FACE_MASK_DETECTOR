{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# ##########################\n",
    "# FUNCTIONS\n",
    "# ##########################\n",
    "\n",
    "def decode_bbox(anchors, raw_outputs, variances=[0.1, 0.1, 0.2, 0.2]):\n",
    "    '''\n",
    "    Decode the actual bbox according to the anchors.\n",
    "    the anchor value order is:[xmin, ymin, xmax, ymax]\n",
    "    :param anchors: numpy array with shape [batch, num_anchors, 4]\n",
    "    :param raw_outputs: numpy array with the same shape with anchors\n",
    "    :param variances: list of float, default=[0.1, 0.1, 0.2, 0.2]\n",
    "    :return:\n",
    "    '''\n",
    "    anchor_centers_x = (anchors[:, :, 0:1] + anchors[:, :, 2:3]) / 2\n",
    "    anchor_centers_y = (anchors[:, :, 1:2] + anchors[:, :, 3:]) / 2\n",
    "    anchors_w = anchors[:, :, 2:3] - anchors[:, :, 0:1]\n",
    "    anchors_h = anchors[:, :, 3:] - anchors[:, :, 1:2]\n",
    "    raw_outputs_rescale = raw_outputs * np.array(variances)\n",
    "    predict_center_x = raw_outputs_rescale[:, :, 0:1] * anchors_w + anchor_centers_x\n",
    "    predict_center_y = raw_outputs_rescale[:, :, 1:2] * anchors_h + anchor_centers_y\n",
    "    predict_w = np.exp(raw_outputs_rescale[:, :, 2:3]) * anchors_w\n",
    "    predict_h = np.exp(raw_outputs_rescale[:, :, 3:]) * anchors_h\n",
    "    predict_xmin = predict_center_x - predict_w / 2\n",
    "    predict_ymin = predict_center_y - predict_h / 2\n",
    "    predict_xmax = predict_center_x + predict_w / 2\n",
    "    predict_ymax = predict_center_y + predict_h / 2\n",
    "    predict_bbox = np.concatenate([predict_xmin, predict_ymin, predict_xmax, predict_ymax], axis=-1)\n",
    "    return predict_bbox\n",
    "\n",
    "def generate_anchors(feature_map_sizes, anchor_sizes, anchor_ratios, offset=0.5):\n",
    "    '''\n",
    "    generate anchors.\n",
    "    :param feature_map_sizes: list of list, for example: [[40,40], [20,20]]\n",
    "    :param anchor_sizes: list of list, for example: [[0.05, 0.075], [0.1, 0.15]]\n",
    "    :param anchor_ratios: list of list, for example: [[1, 0.5], [1, 0.5]]\n",
    "    :param offset: default to 0.5\n",
    "    :return:\n",
    "    '''\n",
    "    anchor_bboxes = []\n",
    "    for idx, feature_size in enumerate(feature_map_sizes):\n",
    "        cx = (np.linspace(0, feature_size[0] - 1, feature_size[0]) + 0.5) / feature_size[0]\n",
    "        cy = (np.linspace(0, feature_size[1] - 1, feature_size[1]) + 0.5) / feature_size[1]\n",
    "        cx_grid, cy_grid = np.meshgrid(cx, cy)\n",
    "        cx_grid_expend = np.expand_dims(cx_grid, axis=-1)\n",
    "        cy_grid_expend = np.expand_dims(cy_grid, axis=-1)\n",
    "        center = np.concatenate((cx_grid_expend, cy_grid_expend), axis=-1)\n",
    "\n",
    "        num_anchors = len(anchor_sizes[idx]) +  len(anchor_ratios[idx]) - 1\n",
    "        center_tiled = np.tile(center, (1, 1, 2* num_anchors))\n",
    "        anchor_width_heights = []\n",
    "\n",
    "        # different scales with the first aspect ratio\n",
    "        for scale in anchor_sizes[idx]:\n",
    "            ratio = anchor_ratios[idx][0] # select the first ratio\n",
    "            width = scale * np.sqrt(ratio)\n",
    "            height = scale / np.sqrt(ratio)\n",
    "            anchor_width_heights.extend([-width / 2.0, -height / 2.0, width / 2.0, height / 2.0])\n",
    "\n",
    "        # the first scale, with different aspect ratios (except the first one)\n",
    "        for ratio in anchor_ratios[idx][1:]:\n",
    "            s1 = anchor_sizes[idx][0] # select the first scale\n",
    "            width = s1 * np.sqrt(ratio)\n",
    "            height = s1 / np.sqrt(ratio)\n",
    "            anchor_width_heights.extend([-width / 2.0, -height / 2.0, width / 2.0, height / 2.0])\n",
    "\n",
    "        bbox_coords = center_tiled + np.array(anchor_width_heights)\n",
    "        bbox_coords_reshape = bbox_coords.reshape((-1, 4))\n",
    "        anchor_bboxes.append(bbox_coords_reshape)\n",
    "        \n",
    "    anchor_bboxes = np.concatenate(anchor_bboxes, axis=0)\n",
    "    return anchor_bboxes\n",
    "\n",
    "def single_class_non_max_suppression(bboxes, confidences, conf_thresh=0.2, iou_thresh=0.5, keep_top_k=-1):\n",
    "    '''\n",
    "    do nms on single class.\n",
    "    Hint: for the specific class, given the bbox and its confidence,\n",
    "    1) sort the bbox according to the confidence from top to down, we call this a set\n",
    "    2) select the bbox with the highest confidence, remove it from set, and do IOU calculate with the rest bbox\n",
    "    3) remove the bbox whose IOU is higher than the iou_thresh from the set,\n",
    "    4) loop step 2 and 3, util the set is empty.\n",
    "    :param bboxes: numpy array of 2D, [num_bboxes, 4]\n",
    "    :param confidences: numpy array of 1D. [num_bboxes]\n",
    "    :param conf_thresh:\n",
    "    :param iou_thresh:\n",
    "    :param keep_top_k:\n",
    "    :return:\n",
    "    '''\n",
    "    if len(bboxes) == 0: return []\n",
    "\n",
    "    conf_keep_idx = np.where(confidences > conf_thresh)[0]\n",
    "\n",
    "    bboxes = bboxes[conf_keep_idx]\n",
    "    confidences = confidences[conf_keep_idx]\n",
    "\n",
    "    pick = []\n",
    "    xmin = bboxes[:, 0]\n",
    "    ymin = bboxes[:, 1]\n",
    "    xmax = bboxes[:, 2]\n",
    "    ymax = bboxes[:, 3]\n",
    "\n",
    "    area = (xmax - xmin + 1e-3) * (ymax - ymin + 1e-3)\n",
    "    idxs = np.argsort(confidences)\n",
    "\n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # keep top k\n",
    "        if keep_top_k != -1:\n",
    "            if len(pick) >= keep_top_k:\n",
    "                break\n",
    "\n",
    "        overlap_xmin = np.maximum(xmin[i], xmin[idxs[:last]])\n",
    "        overlap_ymin = np.maximum(ymin[i], ymin[idxs[:last]])\n",
    "        overlap_xmax = np.minimum(xmax[i], xmax[idxs[:last]])\n",
    "        overlap_ymax = np.minimum(ymax[i], ymax[idxs[:last]])\n",
    "        overlap_w = np.maximum(0, overlap_xmax - overlap_xmin)\n",
    "        overlap_h = np.maximum(0, overlap_ymax - overlap_ymin)\n",
    "        overlap_area = overlap_w * overlap_h\n",
    "        overlap_ratio = overlap_area / (area[idxs[:last]] + area[i] - overlap_area)\n",
    "\n",
    "        need_to_be_deleted_idx = np.concatenate(([last], np.where(overlap_ratio > iou_thresh)[0]))\n",
    "        idxs = np.delete(idxs, need_to_be_deleted_idx)\n",
    "    return conf_keep_idx[pick]\n",
    "\n",
    "def load_pytorch_model(model_path):\n",
    "    model = torch.load(model_path)\n",
    "    return model\n",
    "\n",
    "def pytorch_inference(model, img_arr):\n",
    "    y_bboxes, y_scores, = model.forward(torch.tensor(img_arr).float())\n",
    "    return y_bboxes.detach().numpy(), y_scores.detach().numpy()\n",
    "\n",
    "def logoOverlay(original, watermark, alpha = 0.5, width=500, height=500):\n",
    "    # resize image\n",
    "    #original = cv2.resize(original, (width, height), interpolation = cv2.INTER_AREA)\n",
    "    (originalHeight, originalWidth) = original.shape[:2]\n",
    "    original = np.dstack([original, np.ones((originalHeight,originalWidth), dtype=\"uint8\") * 255])\n",
    "\n",
    "    #Resizing the watermark image\n",
    "    scale = 80\n",
    "    rw = int(watermark.shape[1] * scale / 100)\n",
    "    rh = int(watermark.shape[0] * scale / 100)\n",
    "    dim = (rw,rh)\n",
    "    watermarked = cv2.resize(watermark, dim, interpolation = cv2.INTER_AREA)\n",
    "    (wH, wW) = watermarked.shape[:2]\n",
    "\n",
    "    #Blending\n",
    "    overlay = np.zeros((originalHeight, originalWidth, 4), dtype=\"uint8\")\n",
    "    overlay[10:10 + wH, 10:10 + wW] = watermarked\n",
    "    final = original.copy()\n",
    "    return cv2.addWeighted(overlay,0.5,final,1.0,0,final)\n",
    "\n",
    "def inference(image,\n",
    "              conf_thresh=0.5,\n",
    "              iou_thresh=0.4,\n",
    "              target_shape=(160, 160),\n",
    "              draw_result=True,\n",
    "              show_result=True\n",
    "              ):\n",
    "    '''\n",
    "    Main function of detection inference\n",
    "    :param image: 3D numpy array of image\n",
    "    :param conf_thresh: the min threshold of classification probabity.\n",
    "    :param iou_thresh: the IOU threshold of NMS\n",
    "    :param target_shape: the model input size.\n",
    "    :param draw_result: whether to draw bounding box to the image.\n",
    "    :param show_result: whether to display the image.\n",
    "    :return:\n",
    "    '''\n",
    "    #orig_image = np.copy(image)\n",
    "    output_info = []\n",
    "    height, width, _ = image.shape\n",
    "    image_resized = cv2.resize(image, target_shape)\n",
    "    image_np = image_resized / 255.0  # 4 channels\n",
    "    image_exp = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "    image_transposed = image_exp.transpose((0, 3, 1, 2))\n",
    "\n",
    "    y_bboxes_output, y_cls_output = pytorch_inference(model, image_transposed)\n",
    "    # remove the batch dimension, for batch is always 1 for inference.\n",
    "    y_bboxes = decode_bbox(anchors_exp, y_bboxes_output)[0]\n",
    "    y_cls = y_cls_output[0]\n",
    "    # To speed up, do single class NMS, not multiple classes NMS.\n",
    "    bbox_max_scores = np.max(y_cls, axis=1)\n",
    "    bbox_max_score_classes = np.argmax(y_cls, axis=1)\n",
    "\n",
    "    # keep_idx is the alive bounding box after nms.\n",
    "    keep_idxs = single_class_non_max_suppression(y_bboxes,\n",
    "                                                 bbox_max_scores,\n",
    "                                                 conf_thresh=conf_thresh,\n",
    "                                                 iou_thresh=iou_thresh,\n",
    "                                                 )\n",
    "\n",
    "    for idx in keep_idxs:\n",
    "        conf = float(bbox_max_scores[idx])\n",
    "        class_id = bbox_max_score_classes[idx]\n",
    "        bbox = y_bboxes[idx]\n",
    "        # clip the coordinate, avoid the value exceed the image boundary.\n",
    "        xmin = max(0, int(bbox[0] * width))\n",
    "        ymin = max(0, int(bbox[1] * height))\n",
    "        xmax = min(int(bbox[2] * width), width)\n",
    "        ymax = min(int(bbox[3] * height), height)\n",
    "\n",
    "        if draw_result:\n",
    "            if class_id == 0:\n",
    "                color = (0, 255, 0)\n",
    "            else:\n",
    "                color = (255, 0, 0)\n",
    "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(image, \"%s: %.2f\" % (id2class[class_id], conf), (xmin + 2, ymin - 2), font, 0.8, color, 2)\n",
    "            \n",
    "            # --------------\n",
    "            # Main title\n",
    "            # --------------\n",
    "            this_is_blue = (0, 0, 255)\n",
    "            text = \"Copa Airlines\"\n",
    "            # Get boundary of this text\n",
    "            textsize = cv2.getTextSize(text, font, 1, 2)[0]\n",
    "            # Get coords based on boundary\n",
    "            #textX = int((image_resized.shape[1] - textsize[0]) / 1.4)            \n",
    "            textX = int((image_resized.shape[1] + textsize[0]) / 1.1)\n",
    "            #textY = int((image_resized.shape[0] + textsize[1]) / 2)\n",
    "            textY = int((image_resized.shape[0] + textsize[1]) / 0.84)\n",
    "            # Format the displayed text based on the outcome of the model\n",
    "            cv2.putText(image, text, (textX, textY), font, 0.5, this_is_blue, 2)          \n",
    "                        \n",
    "        output_info.append([class_id, conf, xmin, ymin, xmax, ymax])\n",
    "\n",
    "    if show_result:\n",
    "        Image.fromarray(image).show()\n",
    "        \n",
    "    return output_info\n",
    "\n",
    "\n",
    "def run_on_video(video_path, output_video_name, conf_thresh):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    ##fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    ##fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    ##total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(\"Video open failed.\")\n",
    "        return\n",
    "    \n",
    "    status = True\n",
    "    ##idx = 0 \n",
    "    \n",
    "    while status:\n",
    "        ##start_stamp = time.time()        \n",
    "        status, img_raw = cap.read()                       \n",
    "        img_raw = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "                                           \n",
    "        ##read_frame_stamp = time.time()\n",
    "        if (status):            \n",
    "            inference(img_raw,\n",
    "                      conf_thresh,\n",
    "                      iou_thresh=0.5,\n",
    "                      target_shape=(360, 360),\n",
    "                      draw_result=True,\n",
    "                      show_result=False)        \n",
    "\n",
    "            # Add watermark\n",
    "            #height, width, _ = img_raw.shape\n",
    "            img_raw = cv2.cvtColor(img_raw, cv2.COLOR_RGB2BGR)\n",
    "            watermark = cv2.imread(\"Copa_logo_2.png\", cv2.IMREAD_UNCHANGED)                          \n",
    "            img_raw = logoOverlay(img_raw, watermark, height, width)\n",
    "            \n",
    "            # Show the frame\n",
    "            cv2.imshow(\"FACE MASK DETECTOR - Press 'q' to exit\", img_raw)\n",
    "            \n",
    "            ##cv2.waitKey(1)\n",
    "            ##inference_stamp = time.time()\n",
    "            ##write_frame_stamp = time.time()\n",
    "            ##idx += 1\n",
    "            ##print(\"%d of %d\" % (idx, total_frames))\n",
    "            ##print(\"read_frame:%f, infer time:%f, write time:%f\" % (read_frame_stamp - start_stamp,\n",
    "            ##                                                       inference_stamp - read_frame_stamp,\n",
    "            ##                                                       write_frame_stamp - inference_stamp))\n",
    "                        \n",
    "        # If 'q' is pressed, finish the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "            status = False\n",
    "    \n",
    "    # When everything is done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return status\n",
    "\n",
    "# ##########################\n",
    "# MAIN PROGRAM\n",
    "# ##########################\n",
    "\n",
    "model = load_pytorch_model('model360.pth');\n",
    "\n",
    "# anchor configuration\n",
    "feature_map_sizes = [[45, 45], [23, 23], [12, 12], [6, 6], [4, 4]]\n",
    "anchor_sizes = [[0.04, 0.056], [0.08, 0.11], [0.16, 0.22], [0.32, 0.45], [0.64, 0.72]]\n",
    "anchor_ratios = [[1, 0.62, 0.42]] * 5\n",
    "\n",
    "# generate anchors\n",
    "anchors = generate_anchors(feature_map_sizes, anchor_sizes, anchor_ratios)\n",
    "\n",
    "# for inference , the batch size is 1, the model output shape is [1, N, 4],\n",
    "# so we expand dim for anchors to [1, anchor_num, 4]\n",
    "anchors_exp = np.expand_dims(anchors, axis=0)\n",
    "\n",
    "id2class = {0: 'Mask', 1: 'NoMask'}\n",
    "\n",
    "output_status = True\n",
    "while output_status:\n",
    "    output_status = run_on_video(0, '', conf_thresh=0.8)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
