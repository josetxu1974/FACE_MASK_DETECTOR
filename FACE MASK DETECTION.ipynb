{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################\n",
    "# Author: Jos√© A. Ferreira Queimada\n",
    "# e-mail: joseafq@hotmail.com\n",
    "# Description: \n",
    "#    Detect if a medical face mask is ON or OFF applying\n",
    "#    a pre-trained ResNet50-caffemodel to a video stream\n",
    "# ########################################################\n",
    "# Credits on the model: \n",
    "#   Author: Didi Chuxing\n",
    "#   Github: https://github.com/didi/maskdetection\n",
    "#   Description:\n",
    "#         Developed by DiDi AI team, the mask detection technology is based on DFS face detection algorithm \n",
    "#         and the face attributes recognition algorithm DiDi employs on its platform. \n",
    "#         It uses weighted loss function and data augmentation methods to deal with different mask types and \n",
    "#         uneven mask data during the day and the night.\n",
    "#         The system can identify non-mask images with 99.5 per cent accuracy.\n",
    "#         The model was trained on a dataset of 200,000 faces to ensure its robustness.\n",
    "# ########################################################\n",
    "\n",
    "\n",
    "#Import the neccesary libraries\n",
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "# Labels of network\n",
    "classNames = { 0: 'NO FACE MASK', 1: 'FACE MASK ON'}\n",
    "\n",
    "# Open video file or capture device. \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "args_prototxt = \"face_mask.prototxt\"\n",
    "args_weights = \"face_mask.caffemodel\"\n",
    "\n",
    "# Load the Caffe model \n",
    "# Pass the arguments prototxt and weights to the function, after that we loaded correctly the network.\n",
    "net = cv2.dnn.readNetFromCaffe(args_prototxt, args_weights)\n",
    "\n",
    "# Next, we read the video frame by frame and pass to the frame to network for detections. \n",
    "# With the dnn module is easily to use our deep learning network in OpenCV and make predictions.\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame_resized = cv2.resize(frame,(224,224)) # resize frame for prediction\n",
    "    # Why 224x224?... take a look to face_mask.prototxt \"dimensions\" section. It's the first one.\n",
    "\n",
    "    # MobileNet requires fixed dimensions for input image(s) so we have to ensure that it is resized to 224x224 pixels \n",
    "    blob = cv2.dnn.blobFromImage(frame_resized, 1, (224, 224), (104, 117, 123), False)\n",
    "    \n",
    "    # Set to network the input blob \n",
    "    net.setInput(blob)\n",
    "    \n",
    "    # Prediction of network\n",
    "    detections = net.forward()\n",
    "    \n",
    "    # Accuracy limit\n",
    "    the_limit = 0.9\n",
    "            \n",
    "    # Sort the probabilities (in descending) order, grab the index of the top predicted label, and draw it on the input image\n",
    "    idx = np.argsort(detections[0])[::-1][0]\n",
    "    if (detections[0] < the_limit):\n",
    "        class_id = 0\n",
    "    else:\n",
    "        class_id = 1\n",
    "    \n",
    "    # Setup text\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    this_is_red = (0, 0, 255)\n",
    "    this_is_green = (0, 255, 0)\n",
    "    text = \"{}, {:.2f}%\".format(classNames[class_id], detections[0][idx] * 100)\n",
    "    \n",
    "    # Get boundary of this text\n",
    "    textsize = cv2.getTextSize(text, font, 1, 2)[0]\n",
    "\n",
    "    # Get coords based on boundary\n",
    "    textX = int((frame.shape[1] - textsize[0]) / 1.4)\n",
    "    #textY = int((frame.shape[0] + textsize[1]) / 2)\n",
    "    textY = 35\n",
    "\n",
    "    # Format the displayed text based on the outcome of the model\n",
    "    if (detections[0] < the_limit):\n",
    "        cv2.putText(frame, text, (textX, textY), font, 0.7, this_is_red, 2)\n",
    "    else:\n",
    "        cv2.putText(frame, text, (textX, textY), font, 0.7, this_is_green, 2)\n",
    "    \n",
    "    # Display the image of frame normal and resize to screen.\n",
    "    cv2.imshow(\"FACE MASK DETECTOR - Press 'q' to exit\", frame)\n",
    "\n",
    "    # If 'q' is pressed, finish the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
